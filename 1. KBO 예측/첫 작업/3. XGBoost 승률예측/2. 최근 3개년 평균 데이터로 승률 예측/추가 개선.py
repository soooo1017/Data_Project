import xgboost as xgb
import pandas as pd
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
Final_df = pd.read_excel('/Users/SOO/Desktop/ë°ë¶„ í¬íŠ¸í´ë¦¬ì˜¤/Data_Project/1. KBO ì˜ˆì¸¡/2. ë°ì´í„° ì „ì²˜ë¦¬/ìµœì¢… ë°ì´í„° ì •ë¦¬/Final_KBO_Data_v1.xlsx')


# 2. ìµœê·¼ 3ë…„ í‰ê·  ë°ì´í„° ìƒì„± í•¨ìˆ˜
def calculate_3yr_avg(df, year, columns):
    past_data = df[(df['ì—°ë„'] >= year - 3) & (df['ì—°ë„'] < year)]
    return past_data.groupby('íŒ€ëª…_ë¼ë²¨ë§')[columns].mean().reset_index()


# 3. ì£¼ìš” ìŠ¤íƒ¯ ë³€í™”ìœ¨ ì¶”ê°€ í•¨ìˆ˜
def calculate_feature_change_rate(df, year, features):
    prev_year_data = df[df['ì—°ë„'] == year - 1][['íŒ€ëª…_ë¼ë²¨ë§'] + features].set_index('íŒ€ëª…_ë¼ë²¨ë§')
    current_year_data = df[df['ì—°ë„'] == year][['íŒ€ëª…_ë¼ë²¨ë§'] + features].set_index('íŒ€ëª…_ë¼ë²¨ë§')

    # NaN ë°œìƒ ë°©ì§€ (íŒ€ì´ ìƒˆë¡œ ìƒê²¼ê±°ë‚˜ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°)
    change_rate = (current_year_data - prev_year_data) / prev_year_data
    change_rate = change_rate.reset_index().fillna(0)  # NaN ê°’ 0ìœ¼ë¡œ ì²˜ë¦¬
    change_rate.columns = [f"{col}_ë³€í™”ìœ¨" if col != 'íŒ€ëª…_ë¼ë²¨ë§' else col for col in change_rate.columns]

    return change_rate


# 4. ì‚¬ìš©í•  ë³€ìˆ˜ ì„¤ì •
features = ['WHIP_pitcher', 'R_pitcher', 'BPC_pitcher', 'OPS_hitter', 'R_hitter',
            'AVG_hitter', 'FPCT_defense', 'SB_defense', 'SB_runner', 'SBA_runner']

change_features = ['OPS_hitter', 'R_hitter', 'WHIP_pitcher', 'ERA_pitcher']

y_target = 'ìŠ¹ë¥ '

# 5. í•™ìŠµ ë°ì´í„° ì¤€ë¹„ (2005~2023ë…„)
train_list = []
for year in range(2005, 2024):
    avg_data = calculate_3yr_avg(Final_df, year, features)
    actual_winrate = Final_df[Final_df['ì—°ë„'] == year][['íŒ€ëª…_ë¼ë²¨ë§', 'ìŠ¹ë¥ ']]
    change_rate = calculate_feature_change_rate(Final_df, year, change_features)

    merged_data = avg_data.merge(actual_winrate, on='íŒ€ëª…_ë¼ë²¨ë§', how='left')
    merged_data = merged_data.merge(change_rate, on='íŒ€ëª…_ë¼ë²¨ë§', how='left')

    merged_data['ì—°ë„'] = year
    train_list.append(merged_data)

train_df = pd.concat(train_list, ignore_index=True)

# 6. X, y ì„¤ì •
X_train = train_df.drop(columns=['íŒ€ëª…_ë¼ë²¨ë§', 'ì—°ë„', y_target])
y_train = train_df[y_target]

# 7. XGBoost ëª¨ë¸ í•™ìŠµ
model = xgb.XGBRegressor(n_estimators=120, learning_rate=0.1, max_depth=5)
model.fit(X_train, y_train)

# 8. 2024ë…„ ì˜ˆì¸¡
X_test_2024 = calculate_3yr_avg(Final_df, 2024, features)
change_rate_2024 = calculate_feature_change_rate(Final_df, 2024, change_features)

X_test_2024 = X_test_2024.merge(change_rate_2024, on='íŒ€ëª…_ë¼ë²¨ë§', how='left')
X_test_2024 = X_test_2024.drop(columns=['íŒ€ëª…_ë¼ë²¨ë§'])

y_2024_pred = model.predict(X_test_2024)

# 9. ì˜ˆì¸¡ê°’ ì €ì¥ ë° ì •ê·œí™”
Final_df.loc[Final_df['ì—°ë„'] == 2024, 'ì˜ˆì¸¡_ìŠ¹ë¥ '] = y_2024_pred
Final_df['ì˜ˆì¸¡_ìŠ¹ë¥ _ì •ê·œí™”'] = (Final_df['ì˜ˆì¸¡_ìŠ¹ë¥ '] - Final_df['ì˜ˆì¸¡_ìŠ¹ë¥ '].min()) / (
            Final_df['ì˜ˆì¸¡_ìŠ¹ë¥ '].max() - Final_df['ì˜ˆì¸¡_ìŠ¹ë¥ '].min())

# 10. ì˜ˆì¸¡ ìˆœìœ„ ê³„ì‚°
Final_df['ì˜ˆì¸¡_ìˆœìœ„'] = Final_df[Final_df['ì—°ë„'] == 2024]['ì˜ˆì¸¡_ìŠ¹ë¥ '].rank(ascending=False, method='min')

# 11. ëª¨ë¸ í‰ê°€
mae = mean_absolute_error(y_train, model.predict(X_train))
mse = mean_squared_error(y_train, model.predict(X_train))
r2 = r2_score(y_train, model.predict(X_train))

print(f"ğŸ“Š í‰ê· ì ˆëŒ€ì˜¤ì°¨(MAE): {mae:.4f}")
print(f"ğŸ“Š í‰ê· ì œê³±ì˜¤ì°¨(MSE): {mse:.4f}")
print(f"ğŸ“Š ê²°ì •ê³„ìˆ˜(RÂ²): {r2:.4f}")

# 12. ê²°ê³¼ ì¶œë ¥
print(Final_df[Final_df['ì—°ë„'] == 2024][['íŒ€ëª…', 'ì—°ë„', 'ì˜ˆì¸¡_ìŠ¹ë¥ ', 'ì˜ˆì¸¡_ìŠ¹ë¥ _ì •ê·œí™”', 'ì˜ˆì¸¡_ìˆœìœ„', 'ìŠ¹ë¥ ', 'ìˆœìœ„']])
