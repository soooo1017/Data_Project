import xgboost as xgb
import pandas as pd
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
Final_df = pd.read_excel('/Users/SOO/Desktop/á„ƒá…¦á„‡á…®á†« á„‘á…©á„á…³á„‘á…©á†¯á„…á…µá„‹á…©/Data_Project/1. KBO ì˜ˆì¸¡/2. ë°ì´í„° ì „ì²˜ë¦¬/ìµœì¢… ë°ì´í„° ì •ë¦¬/Final_KBO_Data.xlsx')

# 2. ì„ íƒí•œ ë³€ìˆ˜ë§Œ ì‚¬ìš©
X_selected = ['RBI_hitter', 'WHIP_pitcher', 'ERA_pitcher', 'R_pitcher', 'OPS_hitter',
              'CS_runner', 'CS%_defense', 'BPC_pitcher', 'E_defense', 'SB_runner']
Y = ['ì˜ˆì¸¡_ìŠ¹ë¥ ']

# 3. í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬ (2024ë…„ ì œì™¸)
X_train = Final_df[Final_df['ì—°ë„'] < 2024][X_selected]
y_train = Final_df[Final_df['ì—°ë„'] < 2024][Y]

# 4. 2024ë…„ ë°ì´í„°ë¡œ X_test ìƒì„± (2025ë…„ ì˜ˆì¸¡)
X_test = Final_df[Final_df['ì—°ë„'] == 2024][X_selected]

# 5. XGBoost ëª¨ë¸ í•™ìŠµ
model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)
model.fit(X_train, y_train)

# 6. 2025ë…„ ì˜ˆì¸¡
y_2025_pred = model.predict(X_test)

# 7. ì˜ˆì¸¡ê°’ ì €ì¥
Final_df.loc[Final_df['ì—°ë„'] == 2024, 'ì˜ˆì¸¡_ìŠ¹ë¥ '] = y_2025_pred

# 8. ëª¨ë¸ í‰ê°€
mae = mean_absolute_error(y_train, model.predict(X_train))
mse = mean_squared_error(y_train, model.predict(X_train))
r2 = r2_score(y_train, model.predict(X_train))

# 9. ê²°ê³¼ ì¶œë ¥
print(f"ğŸ“Š í‰ê· ì ˆëŒ€ì˜¤ì°¨(MAE): {mae:.4f}")
print(f"ğŸ“Š í‰ê· ì œê³±ì˜¤ì°¨(MSE): {mse:.4f}")
print(f"ğŸ“Š ê²°ì •ê³„ìˆ˜(RÂ²): {r2:.4f}")

# 10. ì˜ˆì¸¡ê°’ ì¶œë ¥
print(Final_df[Final_df['ì—°ë„'] == 2024][['íŒ€ëª…', 'ì—°ë„', 'ì˜ˆì¸¡_ìŠ¹ë¥ ']])
