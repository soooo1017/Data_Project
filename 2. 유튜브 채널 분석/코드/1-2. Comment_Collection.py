import time
from googleapiclient.discovery import build
from datetime import datetime
import pandas as pd


# YouTube API í‚¤ ì„¤ì •
api_key = 'AIzaSyBqklA_4k7nyCUzvBB72Jg0V14DOMUcW2U' # ê°œì¸ êµ¬ê¸€ API key
youtube = build('youtube', 'v3', developerKey=api_key)

# ì˜ìƒ ë°ì´í„° CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
video_df = pd.read_csv('../2. Data_Preprocessing/ssglanders_video_final.csv')

# ì¡°íšŒìˆ˜ ì»¬ëŸ¼ì„ ìˆ«ìë¡œ ë³€í™˜
video_df['view_count'] = pd.to_numeric(video_df['view_count'], errors='coerce')

# ê²°ì¸¡ì¹˜ ì œê±°
video_df = video_df.dropna(subset=['view_count'])

# ì¡°íšŒìˆ˜ ë†’ì€ 5ê°œ + ë‚®ì€ 5ê°œ ì˜ìƒ ì¶”ì¶œ
top_5 = video_df.sort_values(by='view_count', ascending=False).head(5)
bottom_5 = video_df.sort_values(by='view_count', ascending=True).head(5)

# video_id ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ
target_videos = pd.concat([top_5, bottom_5])
video_ids = target_videos['video_id'].tolist()
top_5_ids = top_5['video_id'].tolist()
bottom_5_ids = bottom_5['video_id'].tolist()

print("ëŒ“ê¸€ ìˆ˜ì§‘í•  ì˜ìƒ ID ëª©ë¡:", video_ids)
print("Top5 ì˜ìƒ ID ëª©ë¡:", top_5_ids)
print("Bottom5 ì˜ìƒ ID ëª©ë¡:", bottom_5_ids)


# ì „ì²´ ëŒ“ê¸€ ë°ì´í„° ì €ì¥ ë¦¬ìŠ¤íŠ¸
all_comments = []

for video_id in video_ids:
    print(f"ğŸ“º {video_id} ëŒ“ê¸€ ìˆ˜ì§‘ ì¤‘...")

    next_page_token = None
    while True:
        try:
            comment_response = youtube.commentThreads().list(
                part="snippet",
                videoId=video_id,
                maxResults=100,  # í•œ ë²ˆì— 100ê°œê¹Œì§€ ê°€ëŠ¥
                pageToken=next_page_token,
                textFormat="plainText"
            ).execute()

            for item in comment_response['items']:
                comment = item['snippet']['topLevelComment']['snippet']
                all_comments.append({
                    'video_id': video_id,
                    'comment_id': item['id'],
                    'author': comment.get('authorDisplayName'),
                    'text': comment.get('textDisplay'),
                    'like_count': comment.get('likeCount'),
                    'published_at': comment.get('publishedAt')
                })

            next_page_token = comment_response.get('nextPageToken')
            if not next_page_token:
                break

            time.sleep(0.1)  # ë„ˆë¬´ ë¹ ë¥¸ í˜¸ì¶œ ë°©ì§€

        except Exception as e:
            print(f"âŒ {video_id} ëŒ“ê¸€ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            break

# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì €ì¥
now = datetime.now().strftime('%Y-%m-%d_%H%M%S')  # ë‚ ì§œ+ì‹œê°„ì„ íŒŒì¼ëª…ìœ¼ë¡œ ì“¸ ìˆ˜ ìˆê²Œ í˜•ì‹í™”

df_comments = pd.DataFrame(all_comments)

# video_id '-'ë¡œ ì‹œì‘í•˜ë©´ ì•ì— ' ë¶™ì´ê¸°
df_comments['video_id'] = df_comments['video_id'].apply(
    lambda x: f"'{x}" if str(x).startswith('-') else x
)

# video_id '-'ë¡œ ì‹œì‘í•˜ë©´ ì•ì— ' ë¶™ì´ê¸°
df_comments['comment_id'] = df_comments['comment_id'].apply(
    lambda x: f"'{x}" if str(x).startswith('-') else x
)


df_comments.to_csv(f'../1. Data_Collection/({now})ssglanders_video_comments.csv',
                   index=False, encoding='utf-8-sig')

print(f"âœ… ì´ {len(df_comments)}ê°œì˜ ëŒ“ê¸€ì„ ì €ì¥í–ˆì–´ìš”!")
